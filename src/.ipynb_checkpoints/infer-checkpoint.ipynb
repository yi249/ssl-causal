{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T15:19:45.852360649Z",
     "start_time": "2023-11-13T15:19:43.552622034Z"
    }
   },
   "outputs": [],
   "source": [
    "#from inference import infer_mnist_cf, get_mnist_obs, get_fig_arr, load_vae, dataloader_hack, get_paths, get_obs_item\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as TF\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,  os.path.abspath(\"../../causal-gen/src/pgm\"))\n",
    "from datasets import morphomnist, mimic\n",
    "from typing import Dict\n",
    "from utils import normalize\n",
    "from pgm.utils_pgm import MidpointNormalize\n",
    "from torch import Tensor, nn\n",
    "from vae import HVAE\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import EMA, seed_all\n",
    "import src.datasets as setup\n",
    "from tqdm import tqdm\n",
    "from classifier import Model as digitclassifier\n",
    "from mimic_classifier import Model as mimicclassifier\n",
    "from predict_pgm import Predictors\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy.stats import beta\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import warnings\n",
    "from io import BytesIO\n",
    "from matplotlib.backends.backend_svg import FigureCanvasSVG\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a057f55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.3363)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = dist.Gamma(10,5)\n",
    "normal = dist.Normal(0,1)\n",
    "gamma.log_prob(9/5) + normal.log_prob(torch.tensor(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299a6b0",
   "metadata": {},
   "source": [
    "## Load VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8472fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hparams:\n",
    "    def update(self, dict):\n",
    "        for k, v in dict.items():\n",
    "            setattr(self, k, v)\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "CUDA = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a34c9a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dig_classifier = digitclassifier()\n",
    "# checkpoint = torch.load(\"model.pth\", map_location=DEVICE)\n",
    "# dig_classifier.load_state_dict(checkpoint)\n",
    "# dig_classifier.eval()\n",
    "    \n",
    "# predictor = Predictors()\n",
    "# pred_checkpoint = torch.load(\"../../causal-gen/checkpoints/f_f_f_b_b_b_t_i_d/pgm_uncor/checkpoint.pt\")\n",
    "# predictor.load_state_dict(pred_checkpoint['ema_model_state_dict'])\n",
    "# predictor.eval()\n",
    "    \n",
    "# data = setup.MorphoMNIST(\n",
    "#     root_dir='../datasets/col_morphomnist/all',\n",
    "#     train=False,\n",
    "#     columns=['fg_r', 'fg_g', 'fg_b', 'bg_r', 'bg_g', 'bg_b', 'thickness', 'intensity', 'digit'],\n",
    "#     norm='[-1,1]',\n",
    "#     concat_pa=False,\n",
    "#     colour=True\n",
    "# )\n",
    "\n",
    "# loader = DataLoader(data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5148ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"Chest\"\n",
    "data_path = \"../../causalssl/datasets/mimic/\"\n",
    "vae_path = \"../checkpoints/f_a_s_r/ssl0.2/checkpoint_0.pt\"\n",
    "eval_path = \"../checkpoints/mimic_classifier/augmentations_lowlr/checkpoint_310.pt\"\n",
    "\n",
    "#eval\n",
    "eval_checkpoint = torch.load(eval_path, map_location=DEVICE)\n",
    "eval_args = Hparams()\n",
    "eval_args.device=DEVICE\n",
    "eval_args.update(eval_checkpoint[\"hparams\"])\n",
    "eval_model = mimicclassifier(eval_args).to(eval_args.device)\n",
    "eval_model.load_state_dict(eval_checkpoint['model_state_dict'])\n",
    "eval_model.eval()\n",
    "\n",
    "\n",
    "#vae            \n",
    "vae_checkpoint = torch.load(vae_path, map_location=DEVICE)\n",
    "vae_args = Hparams()\n",
    "vae_args.device = DEVICE\n",
    "vae_args.update(vae_checkpoint[\"hparams\"])\n",
    "vae = HVAE(vae_args).to(vae_args.device)\n",
    "vae.load_state_dict(vae_checkpoint[\"ema_model_state_dict\"])\n",
    "vae.eval()\n",
    "\n",
    "augmentation = TF.Compose(\n",
    "            [\n",
    "                TF.Resize((vae_args.input_res, vae_args.input_res), antialias=None),\n",
    "                TF.PILToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "data= setup.MIMIC(\n",
    "        data_dir=os.path.join(data_path, \"data\"),\n",
    "        split_path=os.path.join(data_path, f\"meta/less/test_{vae_args.labelled}.csv\"),\n",
    "        cache=False,\n",
    "        parents_x=vae_args.parents_x,\n",
    "        concat_pa=(True if not hasattr(vae_args, \"concat_pa\") else vae_args.concat_pa),\n",
    "        transform=augmentation,\n",
    "    )\n",
    "\n",
    "loader= DataLoader(data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "253661ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.randint(len(data))\n",
    "data[idx]['race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85522273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       " 'finding': tensor([1]),\n",
       " 'age': tensor([0.4800]),\n",
       " 'sex': tensor([0]),\n",
       " 'race': tensor([1, 0, 0])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.randint(len(data))\n",
    "data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1d89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_accuracy():\n",
    "    idx = np.random.randint(10000)\n",
    "    x = torch.unsqueeze(data[idx]['x'].to(torch.float32).to(CUDA), dim=0)/255\n",
    "    pa = {}\n",
    "    for k,v in data[idx].items():\n",
    "        if k != \"x\":\n",
    "            pa[k] = v.to(torch.float32).to(CUDA)\n",
    "    cf_d = torch.tensor(np.random.randint(0,9))\n",
    "    while cf_d == torch.argmax(pa['digit']):\n",
    "        cf_d = torch.tensor(np.random.randint(0,9))\n",
    "    cf_pa = pa.copy()\n",
    "    cf_pa['digit'] = F.one_hot(cf_d, num_classes=10).to(torch.float32).to(CUDA)\n",
    "    cf_pa['fgcol'] = None\n",
    "    cf_pa['bgcol'] = None\n",
    "    output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "    plt.imshow(postprocess(output[\"rec_x\"]).astype(int))\n",
    "#     plt.imshow(postprocess(output[\"cf_x\"]).astype(int))\n",
    "    cf_x = torch.unsqueeze(output[\"cf_x\"][0],0).cpu()+1\n",
    "    pred = torch.argmax(dig_classifier(cf_x*127.5))\n",
    "    correct_digit = cf_d == int(pred)\n",
    "    fg = output['cf_pa']['fgcol'].detach().cpu()/2+0.5\n",
    "    bg = output['cf_pa']['bgcol'].detach().cpu()/2+0.5\n",
    "    preds = predictor.predict(cf_x-1)\n",
    "    return correct_digit, cf_d, torch.squeeze(fg), torch.squeeze(bg), torch.squeeze(preds['fgcol'].detach().cpu()), torch.squeeze(preds['bgcol'].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f8709f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_thickness():\n",
    "    predictor.to(CUDA)\n",
    "    idx = np.random.randint(10000)\n",
    "    x = torch.unsqueeze(data[idx]['x'].to(torch.float32).to(CUDA), dim=0)/255\n",
    "    pa = {}\n",
    "    for k,v in data[idx].items():\n",
    "        if k != \"x\":\n",
    "            pa[k] = v.to(torch.float32).to(CUDA)\n",
    "    cf_t = torch.rand(1)*2 -1\n",
    "    cf_pa = pa.copy()\n",
    "    cf_pa['thickness'] = cf_t.to(CUDA)\n",
    "    cf_pa['intensity'] = None\n",
    "    output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "    intensity = output['cf_pa']['intensity'].detach().cpu()\n",
    "    preds = predictor.predict(torch.unsqueeze(output[\"cf_x\"][0],0))\n",
    "    return torch.squeeze(cf_t/2 + 0.5), torch.squeeze(intensity/2 + 0.5), torch.squeeze(preds['intensity'].detach().cpu())/2+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71e765ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_intensity():\n",
    "    predictor.to(CUDA)\n",
    "    idx = np.random.randint(10000)\n",
    "    x = torch.unsqueeze(data[idx]['x'].to(torch.float32).to(CUDA), dim=0)/255\n",
    "    pre_preds = predictor.predict(x*2-1)\n",
    "    pa = {}\n",
    "    for k,v in data[idx].items():\n",
    "        if k != \"x\":\n",
    "            pa[k] = v.to(torch.float32).to(CUDA)\n",
    "    cf_i = torch.rand(1)*2 -1\n",
    "    cf_pa = pa.copy()\n",
    "    cf_pa['intensity'] = cf_i.to(CUDA)\n",
    "    output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "    thickness = output['cf_pa']['thickness'].detach().cpu()\n",
    "    preds = predictor.predict(torch.unsqueeze(output[\"cf_x\"][0],0))\n",
    "    \n",
    "    return torch.squeeze(pre_preds['thickness'].detach().cpu())/2+0.5, torch.squeeze(preds['thickness'].detach().cpu())/2+0.5, torch.squeeze(cf_i/2 + 0.5), torch.squeeze(preds['intensity'].detach().cpu())/2+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b45c7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchange_intensity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m, in \u001b[0;36mchange_intensity\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchange_intensity\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mto(CUDA)\n\u001b[1;32m      3\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m      4\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(data[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(CUDA), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "change_intensity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec28f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def do_accuracy(samples):\n",
    "    \n",
    "#     SEX_CAT_CHEST = [\"male\", \"female\"]  # 0,1\n",
    "#     RACE_CAT = [\"white\", \"asian\", \"black\"]  # 0,1,2\n",
    "#     FIND_CAT = [\"no disease\", \"pleural effusion\"]\n",
    "    \n",
    "#     r_list=[]\n",
    "#     s_list=[]\n",
    "#     f_list=[]\n",
    "#     a_list=[]\n",
    "#     cf_f=[]\n",
    "#     cf_a=[]\n",
    "#     cf_s=[]\n",
    "#     cf_r=[]\n",
    "#     cf_f_f=[]\n",
    "#     cf_f_a=[]\n",
    "#     cf_f_s=[]\n",
    "#     cf_f_r=[]\n",
    "#     cf_a_f=[]\n",
    "#     cf_a_a=[]\n",
    "#     cf_a_s=[]\n",
    "#     cf_a_r=[]\n",
    "#     cf_s_f=[]\n",
    "#     cf_s_a=[]\n",
    "#     cf_s_s=[]\n",
    "#     cf_s_r=[]\n",
    "#     cf_r_f=[]\n",
    "#     cf_r_a=[]\n",
    "#     cf_r_s=[]\n",
    "#     cf_r_r=[]\n",
    "#     cf_fs=[]\n",
    "#     cf_as=[]\n",
    "#     cf_rs=[]\n",
    "#     cf_ss=[]\n",
    "    \n",
    "#     for i in tqdm(range(samples)):\n",
    "#         idx,x,r,s,f,a = get_chest_obs()\n",
    "#         x = x.to(\"cuda:1\")\n",
    "        \n",
    "#         f_list.append(FIND_CAT.index(f))\n",
    "#         a_list.append(a)\n",
    "#         s_list.append(SEX_CAT_CHEST.index(s))\n",
    "#         r_list.append(RACE_CAT.index(r))\n",
    "\n",
    "#         #finding\n",
    "#         if f == \"no disease\":\n",
    "#             cf_f = \"pleural effusion\" \n",
    "#         else:\n",
    "#             cf_f = \"no disease\"\n",
    "#         cf_x, _, _, _, _, _, _, _ = infer_chest_cf(idx,x,r,s,cf_f,a,True,True,True,True)\n",
    "#         cf_x = torch.unsqueeze(torch.unsqueeze(torch.tensor(cf_x), 0),0).to(torch.float32).to(\"cuda:1\")\n",
    "#         out = eval_model.predict(cf_x)\n",
    "#         cf_fs.append(FIND_CAT.index(cf_f))\n",
    "#         cf_f_f.append(out[0].cpu().detach().numpy())\n",
    "#         cf_f_a.append(out[1].cpu().detach().numpy()*50 + 50)\n",
    "#         cf_f_s.append(out[2].cpu().detach().numpy())\n",
    "#         cf_f_r.append(out[3].cpu().detach().numpy())\n",
    "    \n",
    "\n",
    "#         #age\n",
    "#         cf_a = np.random.randint(100)\n",
    "#         cf_x, _, _, _, _, _, _, _ = infer_chest_cf(idx,x,r,s,f,cf_a,True,True,True,True)\n",
    "#         cf_x = torch.unsqueeze(torch.unsqueeze(torch.tensor(cf_x), 0),0).to(torch.float32).to(\"cuda:1\")\n",
    "#         out = eval_model.predict(cf_x)\n",
    "#         cf_as.append(cf_a)\n",
    "#         cf_a_f.append(out[0].cpu().detach().numpy())\n",
    "#         cf_a_a.append(out[1].cpu().detach().numpy()*50 + 50)\n",
    "#         cf_a_s.append(out[2].cpu().detach().numpy())\n",
    "#         cf_a_r.append(out[3].cpu().detach().numpy())\n",
    "\n",
    "\n",
    "#         #sex\n",
    "#         if s == \"female\":\n",
    "#             cf_s = \"male\"\n",
    "#         else:\n",
    "#             cf_s = \"female\"\n",
    "#         cf_x, _, _, _, _, _, _, _ = infer_chest_cf(idx,x,r,cf_s,f,a,True,True,True,True)\n",
    "#         cf_x = torch.unsqueeze(torch.unsqueeze(torch.tensor(cf_x), 0),0).to(torch.float32).to(\"cuda:1\")\n",
    "#         out = eval_model.predict(cf_x)\n",
    "#         cf_ss.append(SEX_CAT_CHEST.index(cf_s))\n",
    "#         cf_s_f.append(out[0].cpu().detach().numpy())\n",
    "#         cf_s_a.append(out[1].cpu().detach().numpy()*50 + 50)\n",
    "#         cf_s_s.append(out[2].cpu().detach().numpy())\n",
    "#         cf_s_r.append(out[3].cpu().detach().numpy())\n",
    "\n",
    "\n",
    "#         #race\n",
    "#         race_options = RACE_CAT.copy()\n",
    "#         race_options.remove(r)\n",
    "#         cf_r = random.choice(race_options)\n",
    "#         cf_x, _, _, _, _, _, _, _ = infer_chest_cf(idx,x,cf_r,s,f,a,True,True,True,True)\n",
    "#         cf_x = torch.unsqueeze(torch.unsqueeze(torch.tensor(cf_x), 0),0).to(torch.float32).to(\"cuda:1\")\n",
    "#         out = eval_model.predict(cf_x)\n",
    "#         cf_rs.append(RACE_CAT.index(cf_r))\n",
    "#         cf_r_f.append(out[0].cpu().detach().numpy())\n",
    "#         cf_r_a.append(out[1].cpu().detach().numpy()*50 + 50)\n",
    "#         cf_r_s.append(out[2].cpu().detach().numpy())\n",
    "#         cf_r_r.append(out[3].cpu().detach().numpy())\n",
    "    \n",
    "#     one_hot_r = label_binarize(np.array(r_list), classes=[0, 1, 2])\n",
    "#     one_hot_cf_r = label_binarize(np.array(cf_rs), classes=[0, 1, 2])\n",
    "    \n",
    "#     f_f = roc_auc_score(cf_fs, cf_f_f, average=\"macro\")\n",
    "#     print(\"f_f:\", f_f)\n",
    "#     f_a = np.mean(abs(np.array(cf_f_a)-np.array(a_list)))\n",
    "#     print(\"f_a:\", f_a)\n",
    "#     f_s = roc_auc_score(s_list, cf_f_s, average=\"macro\")\n",
    "#     print(\"f_s:\", f_s)\n",
    "\n",
    "#     a_f = roc_auc_score(f_list, cf_a_f, average=\"macro\")\n",
    "#     print(\"a_f:\", a_f)\n",
    "#     a_a = np.mean(abs(np.array(cf_a_a)-np.array(cf_as)))\n",
    "#     print(\"a_a:\", a_a)\n",
    "#     a_s = roc_auc_score(s_list, cf_a_s, average=\"macro\")\n",
    "#     print(\"a_s:\", a_s)\n",
    "    \n",
    "#     s_f = roc_auc_score(f_list, cf_s_f, average=\"macro\")\n",
    "#     print(\"s_f:\", s_f)\n",
    "#     s_a = np.mean(abs(np.array(cf_s_a)-np.array(a_list)))\n",
    "#     print(\"s_a:\", s_a)\n",
    "#     s_s = roc_auc_score(cf_ss, np.array(cf_s_s), average=\"macro\")\n",
    "#     print(\"s_s:\", s_s)\n",
    "    \n",
    "#     r_f = roc_auc_score(f_list, cf_r_f, average=\"macro\")\n",
    "#     print(\"r_f:\", r_f)\n",
    "#     r_a = np.mean(abs(np.array(cf_r_a)-np.array(a_list)))\n",
    "#     print(\"r_a:\", r_a)\n",
    "#     r_s = roc_auc_score(s_list, cf_r_s, average=\"macro\")\n",
    "#     print(\"r_s:\", r_s)\n",
    "    \n",
    "#     f_r = roc_auc_score(one_hot_r, np.squeeze(np.array(cf_f_r)), multi_class=\"ovr\", average=\"macro\")\n",
    "#     print(\"f_r:\", f_r)\n",
    "#     a_r = roc_auc_score(one_hot_r, np.squeeze(np.array(cf_a_r)), multi_class=\"ovr\", average=\"macro\")\n",
    "#     print(\"a_r:\", a_r)\n",
    "#     s_r = roc_auc_score(one_hot_r, np.squeeze(np.array(cf_s_r)), multi_class=\"ovr\", average=\"macro\")\n",
    "#     print(\"s_r\", s_r)\n",
    "#     r_r = roc_auc_score(one_hot_cf_r, np.squeeze(np.array(cf_r_r)), multi_class=\"ovr\", average=\"macro\")\n",
    "#     print(\"r_r\", r_r)\n",
    "    \n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "317631f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_accuracy(samples):\n",
    "    eval_model.to(CUDA)\n",
    "    r_list=[]\n",
    "    s_list=[]\n",
    "    f_list=[]\n",
    "    a_list=[]\n",
    "    cf_f=[]\n",
    "    cf_a=[]\n",
    "    cf_s=[]\n",
    "    cf_r=[]\n",
    "    cf_f_f=[]\n",
    "    cf_f_a=[]\n",
    "    cf_f_s=[]\n",
    "    cf_f_r=[]\n",
    "    cf_a_f=[]\n",
    "    cf_a_a=[]\n",
    "    cf_a_s=[]\n",
    "    cf_a_r=[]\n",
    "    cf_s_f=[]\n",
    "    cf_s_a=[]\n",
    "    cf_s_s=[]\n",
    "    cf_s_r=[]\n",
    "    cf_r_f=[]\n",
    "    cf_r_a=[]\n",
    "    cf_r_s=[]\n",
    "    cf_r_r=[]\n",
    "    cf_fs=[]\n",
    "    cf_as=[]\n",
    "    cf_rs=[]\n",
    "    cf_ss=[]\n",
    "    \n",
    "    for i in tqdm(range(samples)):\n",
    "        \n",
    "        idx = np.random.randint(len(data))\n",
    "        x = torch.unsqueeze(data[idx]['x'].to(torch.float32).to(CUDA), dim=0)/255\n",
    "        pa = {}\n",
    "        for k,v in data[idx].items():\n",
    "            if k != \"x\":\n",
    "                pa[k] = v.to(torch.float32).to(CUDA)\n",
    "\n",
    "        f_list.append(pa['finding'].detach().cpu().numpy())\n",
    "        a_list.append(pa['age'].detach().cpu().numpy())\n",
    "        s_list.append(pa['sex'].detach().cpu().numpy())\n",
    "        r_list.append(torch.argmax(pa['race']).detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        #finding\n",
    "        cf_f = 1-pa['finding']\n",
    "        cf_pa = pa.copy()\n",
    "        cf_pa['finding'] = cf_f.to(CUDA)\n",
    "        output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "        out = eval_model.predict(output['cf_x'])\n",
    "        cf_fs.append(cf_f.detach().cpu().numpy())\n",
    "        cf_f_f.append(out[0].cpu().detach().numpy())\n",
    "        cf_f_a.append(out[1].cpu().detach().numpy()*2-1)\n",
    "        cf_f_s.append(out[2].cpu().detach().numpy())\n",
    "        cf_f_r.append(out[3].cpu().detach().numpy())\n",
    "\n",
    "\n",
    "        #age\n",
    "        cf_a = torch.rand(1)*2 -1\n",
    "        cf_pa = pa.copy()\n",
    "        cf_pa['age'] = cf_a.to(CUDA)\n",
    "        output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "        out = eval_model.predict(output['cf_x'])\n",
    "        cf_as.append(cf_a.detach().cpu().numpy())\n",
    "        cf_a_f.append(out[0].cpu().detach().numpy())\n",
    "        cf_a_a.append(out[1].cpu().detach().numpy()*2-1)\n",
    "        cf_a_s.append(out[2].cpu().detach().numpy())\n",
    "        cf_a_r.append(out[3].cpu().detach().numpy())\n",
    "\n",
    "\n",
    "        #sex\n",
    "        cf_s = 1-pa['sex']\n",
    "        cf_pa = pa.copy()\n",
    "        cf_pa['sex'] = cf_s.to(CUDA)\n",
    "        output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "        out = eval_model.predict(output['cf_x'])\n",
    "        cf_ss.append(cf_s.detach().cpu().numpy())\n",
    "        cf_s_f.append(out[0].cpu().detach().numpy())\n",
    "        cf_s_a.append(out[1].cpu().detach().numpy()*2-1)\n",
    "        cf_s_s.append(out[2].cpu().detach().numpy())\n",
    "        cf_s_r.append(out[3].cpu().detach().numpy())\n",
    "        \n",
    "        \n",
    "        #race\n",
    "        current = torch.argmax(pa['race'])\n",
    "        cf_r = torch.randint(0,2,(1))\n",
    "        while cf_r == current:\n",
    "            cf_r = torch.randint(0,2,(1))\n",
    "        cf_pa = pa.copy()\n",
    "        cf_pa['race'] = cf_r.to(CUDA)\n",
    "        output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "        out = eval_model.predict(output['cf_x'])\n",
    "        cf_rs.append(cf_s.detach().cpu().numpy())\n",
    "        cf_r_f.append(out[0].cpu().detach().numpy())\n",
    "        cf_r_a.append(out[1].cpu().detach().numpy()*2-1)\n",
    "        cf_r_s.append(out[2].cpu().detach().numpy())\n",
    "        cf_r_r.append(out[3].cpu().detach().numpy())\n",
    "    \n",
    "    one_hot_r = label_binarize(np.array(r_list), classes=[0, 1, 2])\n",
    "#     one_hot_cf_r = label_binarize(np.array(cf_rs), classes=[0, 1, 2])\n",
    "    \n",
    "    f_f = roc_auc_score(np.array(cf_fs), np.squeeze(np.array(cf_f_f)), average=\"macro\")\n",
    "    print(\"f_f:\", f_f)\n",
    "    f_a = np.mean(abs(np.array(cf_f_a)-np.array(a_list)))\n",
    "    print(\"f_a:\", f_a*50)\n",
    "    f_s = roc_auc_score(np.array(s_list), np.squeeze(np.array(cf_f_s)), average=\"macro\")\n",
    "    print(\"f_s:\", f_s)\n",
    "    f_r = roc_auc_score(one_hot_r, np.squeeze(np.array(cf_f_r)), multi_class=\"ovr\", average=\"macro\")\n",
    "    print(\"f_r:\", f_r)\n",
    "\n",
    "    a_f = roc_auc_score(np.array(f_list), np.squeeze(np.array(cf_a_f)), average=\"macro\")\n",
    "    print(\"a_f:\", a_f)\n",
    "    a_a = np.mean(abs(np.array(cf_a_a)-np.array(cf_as)))\n",
    "    print(\"a_a:\", a_a*50)\n",
    "    a_s = roc_auc_score(np.array(s_list), np.squeeze(np.array(cf_a_s)), average=\"macro\")\n",
    "    print(\"a_s:\", a_s)\n",
    "    a_r = roc_auc_score(one_hot_r, np.squeeze(np.array(cf_a_r)), multi_class=\"ovr\", average=\"macro\")\n",
    "    print(\"a_r:\", a_r)\n",
    "    \n",
    "    s_f = roc_auc_score(np.array(f_list), np.squeeze(np.array(cf_s_f)), average=\"macro\")\n",
    "    print(\"s_f:\", s_f)\n",
    "    s_a = np.mean(abs(np.array(cf_s_a)-np.array(a_list)))\n",
    "    print(\"s_a:\", s_a*50)\n",
    "    s_s = roc_auc_score(np.array(cf_ss), np.squeeze(np.array(cf_s_s)), average=\"macro\")\n",
    "    print(\"s_s:\", s_s)\n",
    "    s_r = roc_auc_score(one_hot_r, np.squeeze(np.array(cf_s_r)), multi_class=\"ovr\", average=\"macro\")\n",
    "    print(\"s_r\", s_r)\n",
    "    \n",
    "    r_f = roc_auc_score(f_list, cf_r_f, average=\"macro\")\n",
    "    print(\"r_f:\", r_f)\n",
    "    r_a = np.mean(abs(np.array(cf_r_a)-np.array(a_list)))\n",
    "    print(\"r_a:\", r_a*50)\n",
    "    r_s = roc_auc_score(s_list, cf_r_s, average=\"macro\")\n",
    "    print(\"r_s:\", r_s)\n",
    "    r_r = roc_auc_score(one_hot_cf_r, np.squeeze(np.array(cf_r_r)), multi_class=\"ovr\", average=\"macro\")\n",
    "    print(\"r_r\", r_r)\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39454c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                             | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0.], device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                             | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "randint() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdo_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[56], line 89\u001b[0m, in \u001b[0;36mdo_accuracy\u001b[0;34m(samples)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m#race\u001b[39;00m\n\u001b[1;32m     88\u001b[0m current \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(pa[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 89\u001b[0m cf_r \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf_r \u001b[38;5;241m==\u001b[39m current:\n\u001b[1;32m     91\u001b[0m     cf_r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: randint() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "do_accuracy(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_likelihoods(digit,fg,bg):\n",
    "    \n",
    "    fg = torch.clamp(fg, min=0, max=1)\n",
    "    bg = torch.clamp(bg, min=0, max=1)\n",
    "    \n",
    "    a = dist.Beta(torch.FloatTensor([4]), torch.FloatTensor([2]))\n",
    "    b = dist.Beta(torch.FloatTensor([2]), torch.FloatTensor([4]))\n",
    "\n",
    "    #colour\n",
    "    option = digit % 3\n",
    "    if option == 0:\n",
    "        fg_r = a.log_prob(fg[0])\n",
    "        fg_g = b.log_prob(fg[1])\n",
    "        fg_b = b.log_prob(fg[2])\n",
    "        bg_r = b.log_prob(bg[0])\n",
    "        bg_g = a.log_prob(bg[1])\n",
    "        bg_b = b.log_prob(bg[2])\n",
    "    if option == 1:\n",
    "        fg_r = b.log_prob(fg[0])\n",
    "        fg_g = a.log_prob(fg[1])\n",
    "        fg_b = b.log_prob(fg[2])\n",
    "        bg_r = b.log_prob(bg[0])\n",
    "        bg_g = b.log_prob(bg[1])\n",
    "        bg_b = a.log_prob(bg[2])\n",
    "    if option == 2:\n",
    "        fg_r = b.log_prob(fg[0])\n",
    "        fg_g = b.log_prob(fg[1])\n",
    "        fg_b = a.log_prob(fg[2])\n",
    "        bg_r = a.log_prob(bg[0])\n",
    "        bg_g = b.log_prob(bg[1])\n",
    "        bg_b = b.log_prob(bg[2])\n",
    "    fg_ll = fg_r+fg_g+fg_b\n",
    "    bg_ll = bg_r+bg_g+bg_b\n",
    "\n",
    "    return (fg_ll.cpu().numpy(), bg_ll.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4056b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_likelihood(thickness, intensity):\n",
    "    \n",
    "    thickness = thickness * (6.255515-0.87598526) + 0.87598526\n",
    "    intensity = intensity * (254.90317-66.601204) + 66.601204\n",
    "    \n",
    "    gamma = dist.Gamma(torch.tensor([10.0]), torch.tensor([5.0]))\n",
    "    t_ll = torch.squeeze(gamma.log_prob(thickness-0.5))\n",
    "    \n",
    "    def inv_sigmoid(x):\n",
    "        return torch.log(x/(1-x))\n",
    "\n",
    "    i_norm = inv_sigmoid((intensity-64)/191)\n",
    "    i_norm = 2*(i_norm+5-2*thickness)\n",
    "    if i_norm == i_norm:\n",
    "        i_ll = dist.Normal(0,1).log_prob(i_norm)\n",
    "        return i_ll.cpu().numpy() + t_ll.cpu().numpy()\n",
    "    else:\n",
    "        return -float('inf')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaa05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(x: Tensor):\n",
    "    x = (x.permute(0, 2, 3, 1) + 1.0) * 127.5  # channels last, [0,255]\n",
    "    return x.detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ef83b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CUDA = \"cuda:0\"\n",
    "models = [\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/1000_i_0.50scm5_10/checkpoint_57.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/1000_t_0.50scm5_10/checkpoint_34.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/1000_i_scm5_10/checkpoint_33.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/1000_t_scm5_10/checkpoint_31.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/1000scm5_10/checkpoint_35.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/2000scm5_10/checkpoint_45.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/3000scm5_10/checkpoint_30.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/4000scm5_10/checkpoint_15.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/5000scm5_10/checkpoint_40.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/0_1000/checkpoint_40.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/0_2000/checkpoint_5.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/0_0.05scm0_10/checkpoint_62.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/0_4000/checkpoint_55.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/0_5000/checkpoint_55.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/0_0.1scm5_10/checkpoint_70.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/0_500/checkpoint_25.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/0_600/checkpoint_25.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/500scm5_10/checkpoint_60.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/600scm5_10/checkpoint_25.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/100_0.01/checkpoint_10.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/200_0.01/checkpoint_15.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/300_0.01/checkpoint_20.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/400_0.01/checkpoint_30.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/final/500_0.01/checkpoint_35.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/t0.001_i0.049/checkpoint_40.pt\",\n",
    "        \"../checkpoints/f_f_f_b_b_b_t_i_d/t0.005_i0.045/checkpoint_70.pt\",\n",
    "        \"../checkpoints/f_f_f_b_b_b_t_i_d/t0.01_i0.04/checkpoint_75.pt\",\n",
    "        \"../checkpoints/f_f_f_b_b_b_t_i_d/t0.02_i0.03/checkpoint_80.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/t0.025_i0.025/checkpoint_15.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/t0.03_i0.02/checkpoint_40.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/t0.04_i0.01/checkpoint_5.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/t0.045_i0.005/checkpoint_5.pt\",\n",
    "#         \"../checkpoints/f_f_f_b_b_b_t_i_d/t0.049_i0.001/checkpoint_45.pt\",\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    dataset_id = \"CMMNIST\"\n",
    "    data_path = \"../datasets/col_morphomnist/all\"\n",
    "    vae_path = model\n",
    "\n",
    "    vae_checkpoint = torch.load(vae_path, map_location=DEVICE)\n",
    "    vae_args = Hparams()\n",
    "    vae_args.device = DEVICE\n",
    "    vae_args.update(vae_checkpoint[\"hparams\"])\n",
    "    vae = HVAE(vae_args).to(vae_args.device)\n",
    "    vae.load_state_dict(vae_checkpoint[\"ema_model_state_dict\"])\n",
    "    vae.eval()\n",
    "\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     colours = pd.DataFrame(columns=['Digit', 'FG', 'BG', 'FGPRED', 'BGPRED'])\n",
    "    t_i = pd.DataFrame(columns=['Thickness', 'Intensity', 'IntensityPred', \"ThicknessErr\", \"IntensityErr\"])\n",
    "\n",
    "    for i in tqdm(range(1000)):\n",
    "        try:\n",
    "#             correct_digit, digit, fg, bg, fg_pred, bg_pred = digit_accuracy()\n",
    "            t, i, i_pred = change_thickness()\n",
    "            a,b,c,d = change_intensity()\n",
    "            t_err = abs(a-b)\n",
    "            i_err = abs(c-d)\n",
    "        except:\n",
    "            CUDA = \"cuda:1\"\n",
    "#             correct_digit, digit, fg, bg, fg_pred, bg_pred = digit_accuracy()\n",
    "            t, i, i_pred = change_thickness()\n",
    "            a,b,c,d = change_intensity()\n",
    "            t_err = abs(a-b)\n",
    "            i_err = abs(c-d)\n",
    "            CUDA = \"cuda:0\"\n",
    "        \n",
    "#         correct+=correct_digit\n",
    "#         total+=1\n",
    "        \n",
    "#         colours.loc[len(colours.index)] = [digit, fg, bg, fg_pred, bg_pred]\n",
    "        t_i.loc[len(t_i.index)] = [t, i, i_pred, t_err, i_err]\n",
    "        \n",
    "#     #colour\n",
    "#     a = colours.apply(lambda x: colour_likelihoods(x['Digit'],torch.tensor(x['FG']),torch.tensor(x['BG'])), axis=1)\n",
    "#     colours[\"FG LL\"] = [a[i][0] for i in range(len(a))]\n",
    "#     colours[\"BG LL\"] = [a[i][1] for i in range(len(a))]\n",
    "#     fg_ll = [x[0] for x in colours[\"FG LL\"] if x[0] != -np.inf]\n",
    "#     bg_ll = [x[0] for x in colours[\"BG LL\"] if x[0] != -np.inf]\n",
    "    \n",
    "#     b = colours.apply(lambda x: colour_likelihoods(x['Digit'],torch.tensor(x['FGPRED']),torch.tensor(x['BGPRED'])), axis=1)\n",
    "#     colours[\"FGPRED LL\"] = [b[i][0] for i in range(len(b))]\n",
    "#     colours[\"BGPRED LL\"] = [b[i][1] for i in range(len(b))]\n",
    "#     fg_pred_ll = [x[0] for x in colours[\"FGPRED LL\"] if x[0] != -np.inf]\n",
    "#     bg_pred_ll = [x[0] for x in colours[\"BGPRED LL\"] if x[0] != -np.inf]\n",
    "    \n",
    "    #intensity\n",
    "    t_i[\"I LL\"] = t_i.apply(lambda x: intensity_likelihood(x['Thickness'],torch.tensor(x['Intensity'])), axis=1)\n",
    "    i_ll = [x for x in t_i[\"I LL\"] if x != -np.inf]\n",
    "    t_i[\"IPRED LL\"] = t_i.apply(lambda x: intensity_likelihood(x['Thickness'],torch.tensor(x['IntensityPred'])), axis=1)\n",
    "    i_pred_ll = [x for x in t_i[\"IPRED LL\"] if x != -np.inf]\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(model, np.mean(i_ll), np.mean(i_pred_ll), np.mean(t_i[\"ThicknessErr\"]), np.mean(t_i[\"IntensityErr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92dd80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vae_path = \"../checkpoints/f_f_f_b_b_b_t_i_d/final/0_5000/checkpoint_55.pt\"\n",
    "\n",
    "# vae_checkpoint = torch.load(vae_path, map_location=DEVICE)\n",
    "# vae_args = Hparams()\n",
    "# vae_args.device = DEVICEt_i[\"I LL\"] = t_i.apply(lambda x: intensity_likelihood(x['Thickness'],torch.tensor(x['Intensity'])), axis=1)\n",
    "i_ll = [x for x in t_i[\"I LL\"] if x != -np.inf]\n",
    "\n",
    "t_i[\"IPRED LL\"] = t_i.apply(lambda x: intensity_likelihood(x['Thickness'],torch.tensor(x['IntensityPred'])), axis=1)\n",
    "\n",
    "#     colours[\"IPRED LL\"] = [a[i][1] for i in range(len(a))]\n",
    "i_pred_ll = [x for x in t_i[\"IPRED LL\"] if x != -np.inf]\n",
    "#     bg_pred_ll = [x[0] for x in colours[\"IPRED LL\"] if x[0] != -np.inf]\n",
    "\n",
    "#     print(model, correct, total, prop, np.mean(fg_ll), np.mean(bg_ll), np.mean(fg_pred_ll), np.mean(bg_pred_ll))\n",
    "\n",
    "print(np.mean(i_ll), np.mean(i_pred_ll))\n",
    "# vae_args.update(vae_checkpoint[\"hparams\"])\n",
    "# vae = HVAE(vae_args).to(vae_args.device)\n",
    "# vae.load_state_dict(vae_checkpoint[\"ema_model_state_dict\"])\n",
    "\n",
    "t_i = pd.DataFrame(columns=['Thickness', 'Intensity', 'IntensityPred'])\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    try:\n",
    "#             correct_digit, digit, fg, bg, fg_pred, bg_pred = digit_accuracy()\n",
    "        t, i, i_pred = change_thickness()\n",
    "    except:\n",
    "        CUDA = \"cuda:1\"\n",
    "#             correct_digit, digit, fg, bg, fg_pred, bg_pred = digit_accuracy()\n",
    "        t, i, i_pred = change_thickness()\n",
    "        CUDA = \"cuda:0\"\n",
    "\n",
    "    t_i.loc[len(t_i.index)] = [t, i, i_pred]\n",
    "\n",
    "# prop = np.array(correct)/np.array(total)\n",
    "\n",
    "t_i[\"I LL\"] = t_i.apply(lambda x: intensity_likelihood(x['Thickness'],torch.tensor(x['Intensity'])), axis=1)\n",
    "i_ll = [x for x in t_i[\"I LL\"] if x != -np.inf]\n",
    "\n",
    "t_i[\"IPRED LL\"] = t_i.apply(lambda x: intensity_likelihood(x['Thickness'],torch.tensor(x['IntensityPred'])), axis=1)\n",
    "\n",
    "#     colours[\"IPRED LL\"] = [a[i][1] for i in range(len(a))]\n",
    "i_pred_ll = [x for x in t_i[\"IPRED LL\"] if x != -np.inf]\n",
    "#     bg_pred_ll = [x[0] for x in colours[\"IPRED LL\"] if x[0] != -np.inf]\n",
    "\n",
    "#     print(model, correct, total, prop, np.mean(fg_ll), np.mean(bg_ll), np.mean(fg_pred_ll), np.mean(bg_pred_ll))\n",
    "\n",
    "print(np.mean(i_ll), np.mean(i_pred_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc06480",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CUDA=\"cuda:0\"\n",
    "digit_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1876ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA=\"cuda:0\"\n",
    "sample = next(iter(loader))\n",
    "sample['x'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c6f24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vae_args.save_dir = \"../plots\"\n",
    "write_images(vae_args, vae, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b75b506",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lls = np.array([0.3443788, 0.39378393, 0.3635708, 0.38564494, 0.36556232, 0.38201138, 0.36544335, 0.37705284, 0.37605104, 0.37364778, 0.3709293, 0.38255656, 0.37310362, 0.38148555])\n",
    "lls*3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea2bc4",
   "metadata": {},
   "source": [
    "## Counterfactual Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4d5c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(variable):\n",
    "    expanded = variable[..., None, None].repeat(1, 1, *(32,) * 2)\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750a18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(x: Tensor):\n",
    "    x = (x.permute(0, 2, 3, 1) + 1.0) * 127.5  # channels last, [0,255]\n",
    "    return x.detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "245cf244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.unsqueeze(data[1]['x'].to(torch.float32).to(CUDA), dim=0)/255\n",
    "pa = {}\n",
    "for k,v in data[1].items():\n",
    "    if k != \"x\":\n",
    "        pa[k] = expand(v.to(torch.float32).to(CUDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af930cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdce0c9dff0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = torch.squeeze(x).cpu().detach().numpy()#.astype(int)\n",
    "plt.imshow(np.moveaxis(image, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8405508",
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = torch.concat([v.to(CUDA) for v in pa.values()], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa4135fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 7, 7], expected input[1, 3, 32, 32] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vae\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 2\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabduct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m z \u001b[38;5;241m=\u001b[39m [z[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m)]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#z = [z[i][\"z\"] for i in range(20)]\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/causalssl/src/vae.py:1106\u001b[0m, in \u001b[0;36mHVAE.abduct\u001b[0;34m(self, x, parents, cf_parents, alpha, t)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mabduct\u001b[39m(\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1100\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     t: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1105\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tensor]:\n\u001b[0;32m-> 1106\u001b[0m     acts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;66;03m# parents,_,_ = self.ssl.losses(acts, parents)\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m     _, q_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m   1109\u001b[0m         x\u001b[38;5;241m=\u001b[39macts, parents\u001b[38;5;241m=\u001b[39mparents, abduct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, t\u001b[38;5;241m=\u001b[39mt\n\u001b[1;32m   1110\u001b[0m     )  \u001b[38;5;66;03m# q(z|x,pa)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hvae/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hvae/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/causalssl/src/vae.py:144\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mint\u001b[39m, Tensor]:\n\u001b[0;32m--> 144\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     acts \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n",
      "File \u001b[0;32m~/miniconda3/envs/hvae/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hvae/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hvae/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hvae/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 7, 7], expected input[1, 3, 32, 32] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "z = vae.abduct(x*2-1, parents)\n",
    "z = [z[i] for i in range(20)]\n",
    "#z = [z[i][\"z\"] for i in range(20)]\n",
    "recon,_ = vae.forward_latents(latents=z, parents=parents, t=1)\n",
    "plt.imshow(postprocess(recon).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample,_ = vae.sample(parents=parents, return_loc=True, t=1)\n",
    "# plt.imshow(postprocess(sample).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26937987",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_path = \"../checkpoints/f_f_f_b_b_b_t_i_d/final/5000_0.10scm5_10/checkpoint_35.pt\"\n",
    "\n",
    "vae_checkpoint = torch.load(vae_path, map_location=DEVICE)\n",
    "vae_args = Hparams()\n",
    "vae_args.device = DEVICE\n",
    "vae_args.update(vae_checkpoint[\"hparams\"])\n",
    "vae = HVAE(vae_args).to(vae_args.device)\n",
    "vae.load_state_dict(vae_checkpoint[\"ema_model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ad68cd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expand' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;241m159\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m         pa[k] \u001b[38;5;241m=\u001b[39m \u001b[43mexpand\u001b[49m(v\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(CUDA))\n\u001b[1;32m      9\u001b[0m parents \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([v\u001b[38;5;241m.\u001b[39mto(CUDA) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mvalues()], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m z \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mabduct(x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, parents)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expand' is not defined"
     ]
    }
   ],
   "source": [
    "CUDA = \"cuda:1\"\n",
    "x = torch.unsqueeze(data[159]['x'].to(torch.float32).to(CUDA), dim=0)/255\n",
    "pa = {}\n",
    "for k,v in data[159].items():\n",
    "    if k != \"x\":\n",
    "        pa[k] = expand(v.to(torch.float32).to(CUDA))\n",
    "\n",
    "\n",
    "parents = torch.concat([v.to(CUDA) for v in pa.values()], dim=1)\n",
    "z = vae.abduct(x*2-1, parents)\n",
    "z = [z[i] for i in range(20)]\n",
    "#z = [z[i][\"z\"] for i in range(20)]\n",
    "recon,_ = vae.forward_latents(latents=z, parents=parents, t=1)\n",
    "\n",
    "vae.eval()\n",
    "\n",
    "for k,v in pa.items():\n",
    "    if v.dim() > 2:\n",
    "        pa[k] = v[...,0,0]\n",
    "\n",
    "cf_images = [postprocess(recon)]\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['digit'] = F.one_hot(torch.tensor(0), num_classes=10).to(torch.float32).to(CUDA)\n",
    "cf_pa['fgcol'] = None #torch.tensor([-1.,1.,1.])\n",
    "cf_pa['bgcol'] = None #torch.tensor([1.,-1.,1.])\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['digit'] = F.one_hot(torch.tensor(5), num_classes=10).to(torch.float32).to(CUDA)\n",
    "cf_pa['fgcol'] = None #torch.tensor([-1.,1.,1.])\n",
    "cf_pa['bgcol'] = None #torch.tensor([1.,-1.,1.])\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['fgcol'] = torch.rand(1,3).to(CUDA)\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['digit'] = F.one_hot(torch.tensor(1), num_classes=10).to(torch.float32).to(CUDA)\n",
    "cf_pa['fgcol'] = None #torch.tensor([-1.,1.,1.])\n",
    "cf_pa['bgcol'] = None #torch.tensor([1.,-1.,1.])\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['digit'] = F.one_hot(torch.tensor(6), num_classes=10).to(torch.float32).to(CUDA)\n",
    "cf_pa['fgcol'] = None #torch.tensor([-1.,1.,1.])\n",
    "cf_pa['bgcol'] = None #torch.tensor([1.,-1.,1.])\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['bgcol'] = torch.rand(1,3).to(CUDA)\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['digit'] = F.one_hot(torch.tensor(2), num_classes=10).to(torch.float32).to(CUDA)\n",
    "cf_pa['fgcol'] = None #torch.tensor([-1.,1.,1.])\n",
    "cf_pa['bgcol'] = None #torch.tensor([1.,-1.,1.])\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['digit'] = F.one_hot(torch.tensor(7), num_classes=10).to(torch.float32).to(CUDA)\n",
    "cf_pa['fgcol'] = None #torch.tensor([-1.,1.,1.])\n",
    "cf_pa['bgcol'] = None #torch.tensor([1.,-1.,1.])\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['thickness'] = torch.tensor([1.]).to(CUDA)\n",
    "cf_pa['intensity'] = None\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['digit'] = F.one_hot(torch.tensor(3), num_classes=10).to(torch.float32).to(CUDA)\n",
    "cf_pa['fgcol'] = None #torch.tensor([-1.,1.,1.])\n",
    "cf_pa['bgcol'] = None #torch.tensor([1.,-1.,1.])\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['digit'] = F.one_hot(torch.tensor(8), num_classes=10).to(torch.float32).to(CUDA)\n",
    "cf_pa['fgcol'] = None #torch.tensor([-1.,1.,1.])\n",
    "cf_pa['bgcol'] = None #torch.tensor([1.,-1.,1.])\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['intensity'] = torch.tensor([-1.]).to(CUDA)\n",
    "cf_pa['thickness'] = torch.tensor([0.2]).to(CUDA)\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['digit'] = F.one_hot(torch.tensor(4), num_classes=10).to(torch.float32).to(CUDA)\n",
    "cf_pa['fgcol'] = None #torch.tensor([-1.,1.,1.])\n",
    "cf_pa['bgcol'] = None #torch.tensor([1.,-1.,1.])\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "\n",
    "cf_pa = pa.copy()\n",
    "cf_pa['digit'] = F.one_hot(torch.tensor(9), num_classes=10).to(torch.float32).to(CUDA)\n",
    "cf_pa['fgcol'] = None #torch.tensor([-1.,1.,1.])\n",
    "cf_pa['bgcol'] = None #torch.tensor([1.,-1.,1.])\n",
    "output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "cf_images.append(postprocess(output[\"cf_x\"]))\n",
    "    \n",
    "\n",
    "cf_images = np.array(cf_images)\n",
    "output_image = np.concatenate(cf_images, axis=0).reshape((5,3,32,32,3)).transpose([1,2,0,3,4]).reshape((96,160,3))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis('off')\n",
    "# Display the NumPy array as an image\n",
    "ax.imshow(output_image/255, cmap='viridis', interpolation='none')\n",
    "\n",
    "# Save the figure to an SVG file using BytesIO\n",
    "svg_buffer = BytesIO()\n",
    "plt.savefig(svg_buffer, format='svg', bbox_inches='tight', pad_inches=0)\n",
    "svg_buffer.seek(0)\n",
    "\n",
    "# Write the SVG buffer to the output file\n",
    "with open(\"../plots/cmmnist.svg\", 'wb') as svg_file:\n",
    "    svg_file.write(svg_buffer.read())\n",
    "\n",
    "\n",
    "plt.imshow(output_image.astype(int))\n",
    "# output[\"cf_pa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84f6b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recon_image = postprocess(output[\"rec_x\"])\n",
    "plt.imshow(recon_image.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b16938f1e4630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T15:19:47.193252364Z",
     "start_time": "2023-11-13T15:19:46.568286755Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DIGITS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "# idx,x,t,i,y,fgcol,bgcol,obs = get_mnist_obs(dataset_id=dataset_id)\n",
    "# print('Thickness:', t)\n",
    "# print('Intensity:', i)\n",
    "# print('Digit:', y)\n",
    "# print('Foreground Colour:', fgcol)\n",
    "# print('Background Colour:', bgcol)\n",
    "# t = torch.tensor(t)\n",
    "# i = torch.tensor(i)\n",
    "# y = F.one_hot(torch.tensor(DIGITS.index(y)), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b63cbff42f95a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T15:19:49.771666011Z",
     "start_time": "2023-11-13T15:19:47.183893672Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cfs = infer_mnist_cf(idx,None,0.8,255,'8',np.array([148,0,211]),np.array([0,255,255]),0,0,1,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116e652",
   "metadata": {},
   "source": [
    "## Likelihood Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7421d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_accuracy():\n",
    "    idx = np.random.randint(10000)\n",
    "    x = torch.unsqueeze(data[idx]['x'].to(torch.float32).to(CUDA), dim=0)/255\n",
    "    pa = {}\n",
    "    for k,v in data[idx].items():\n",
    "        if k != \"x\":\n",
    "            pa[k] = v.to(torch.float32).to(CUDA)\n",
    "    cf_d = torch.tensor(np.random.randint(0,9))\n",
    "    cf_pa = pa.copy()\n",
    "    cf_pa['digit'] = F.one_hot(cf_d, num_classes=10).to(torch.float32).to(CUDA)\n",
    "    cf_pa['fgcol'] = None\n",
    "    cf_pa['bgcol'] = None\n",
    "    output = vae.counterfactual(x*2-1,parents=pa,cf_pa=cf_pa)\n",
    "    plt.imshow(postprocess(output[\"cf_x\"]).astype(int))\n",
    "    cf_x = output[\"cf_x\"][0].cpu()+1\n",
    "    pred = torch.argmax(classifier(cf_x*127.5))\n",
    "    correct_digit = cf_d == int(pred)\n",
    "    fg = output['cf_pa']['fgcol'].detach().cpu()/2+0.5\n",
    "    bg = output['cf_pa']['bgcol'].detach().cpu()/2+0.5\n",
    "    return correct_digit, cf_d, torch.squeeze(fg), torch.squeeze(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197f2d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "digit_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e23e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "colours = pd.DataFrame(columns=['Digit', 'FG', 'BG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c03efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_likelihoods(digit,fg,bg):\n",
    "    \n",
    "    fg = torch.clamp(fg, min=0, max=1)\n",
    "    bg = torch.clamp(bg, min=0, max=1)\n",
    "    \n",
    "    a = dist.Beta(torch.FloatTensor([4]), torch.FloatTensor([2]))\n",
    "    b = dist.Beta(torch.FloatTensor([2]), torch.FloatTensor([4]))\n",
    "\n",
    "#     def inv_sigmoid(x):\n",
    "#         return torch.log(x/(1-x))\n",
    "\n",
    "#     #intensity\n",
    "#     thickness = pa_preds[:,0]\n",
    "#     intensity = pa_preds[:,1]\n",
    "#     i_norm = inv_sigmoid((intensity-64)/191)\n",
    "#     i_norm = 2*(i_norm+5-2*thickness)\n",
    "#     i_ll = dist.Normal(0,1).log_prob(i_norm)\n",
    "\n",
    "\n",
    "    #colour\n",
    "    option = digit % 3\n",
    "    if option == 0:\n",
    "        fg_r = a.log_prob(fg[0])\n",
    "        fg_g = b.log_prob(fg[1])\n",
    "        fg_b = b.log_prob(fg[2])\n",
    "        bg_r = b.log_prob(bg[0])\n",
    "        bg_g = a.log_prob(bg[1])\n",
    "        bg_b = b.log_prob(bg[2])\n",
    "    if option == 1:\n",
    "        fg_r = b.log_prob(fg[0])\n",
    "        fg_g = a.log_prob(fg[1])\n",
    "        fg_b = b.log_prob(fg[2])\n",
    "        bg_r = b.log_prob(bg[0])\n",
    "        bg_g = b.log_prob(bg[1])\n",
    "        bg_b = a.log_prob(bg[2])\n",
    "    if option == 2:\n",
    "        fg_r = b.log_prob(fg[0])\n",
    "        fg_g = b.log_prob(fg[1])\n",
    "        fg_b = a.log_prob(fg[2])\n",
    "        bg_r = a.log_prob(bg[0])\n",
    "        bg_g = b.log_prob(bg[1])\n",
    "        bg_b = b.log_prob(bg[2])\n",
    "    fg_ll = fg_r+fg_g+fg_b\n",
    "    bg_ll = bg_r+bg_g+bg_b\n",
    "\n",
    "    return (fg_ll.cpu().numpy(), bg_ll.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a4e16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    correct_digit, digit, fg, bg = digit_accuracy()\n",
    "    correct += correct_digit\n",
    "    total += 1\n",
    "    colours.loc[len(colours.index)] = [digit, fg, bg]\n",
    "print(correct)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4456845",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = colours.apply(lambda x: colour_likelihoods(x['Digit'],torch.tensor(x['FG']),torch.tensor(x['BG'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours[\"FG LL\"] = [a[i][0] for i in range(len(a))]\n",
    "colours[\"BG LL\"] = [a[i][1] for i in range(len(a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_ll = [x[0] for x in colours[\"FG LL\"] if x[0] != -np.inf]\n",
    "print(\"fg:\", np.mean(fg_ll))\n",
    "bg_ll = [x[0] for x in colours[\"BG LL\"] if x[0] != -np.inf]\n",
    "print(\"bg:\", np.mean(bg_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df48ef4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zero = list(colours[colours[\"Digit\"] == 0][\"FG\"])\n",
    "zero_r = [zero[i][0] for i in range(len(zero))]\n",
    "zero_g = [zero[i][1] for i in range(len(zero))]\n",
    "zero_b = [zero[i][2] for i in range(len(zero))] \n",
    "fig, ax = plt.subplots(1, 3)\n",
    "a, b = 4,2\n",
    "x = np.linspace(beta.ppf(0.01, a, b), beta.ppf(0.99, a, b), 100)\n",
    "y = np.linspace(beta.ppf(0.01, b, a), beta.ppf(0.99, b, a), 100)\n",
    "ax[0].plot(x, beta.pdf(x, a, b),'r-', lw=5, alpha=0.6, label='zero red')\n",
    "ax[0].hist(zero_r, density=True)\n",
    "ax[1].plot(y, beta.pdf(y, b, a),'r-', lw=5, alpha=0.6, label='zero green')\n",
    "ax[1].hist(zero_g, density=True)\n",
    "ax[2].plot(y, beta.pdf(y, b, a),'r-', lw=5, alpha=0.6, label='zero blue')\n",
    "ax[2].hist(zero_b, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f564b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = list(colours[colours[\"Digit\"] == 1][\"FG\"])\n",
    "one_r = [one[i][0] for i in range(len(one))]\n",
    "one_g = [one[i][1] for i in range(len(one))]\n",
    "one_b = [one[i][2] for i in range(len(one))] \n",
    "fig, ax = plt.subplots(1, 3)\n",
    "a, b = 4,2\n",
    "x = np.linspace(beta.ppf(0.01, a, b), beta.ppf(0.99, a, b), 100)1000\n",
    "y = np.linspace(beta.ppf(0.01, b, a), beta.ppf(0.99, b, a), 100)\n",
    "ax[0].plot(y, beta.pdf(y, b, a),'r-', lw=5, alpha=0.6, label='one red')\n",
    "ax[0].hist(one_r, density=True)\n",
    "ax[1].plot(x, beta.pdf(x, a, b),'r-', lw=5, alpha=0.6, label='one green')\n",
    "ax[1].hist(one_g, density=True)\n",
    "ax[2].plot(y, beta.pdf(y, b, a),'r-', lw=5, alpha=0.6, label='one blue')\n",
    "ax[2].hist(one_b, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba0688",
   "metadata": {},
   "outputs": [],
   "source": [
    "two = list(colours[colours[\"Digit\"] == 2][\"FG\"])\n",
    "two_r = [two[i][0] for i in range(len(two))]\n",
    "two_g = [two[i][1] for i in range(len(two))]\n",
    "two_b = [two[i][2] for i in range(len(two))] \n",
    "fig, ax = plt.subplots(1, 3)\n",
    "a, b = 4,2\n",
    "x = np.linspace(beta.ppf(0.01, a, b), beta.ppf(0.99, a, b), 100)\n",
    "y = np.linspace(beta.ppf(0.01, b, a), beta.ppf(0.99, b, a), 100)\n",
    "ax[0].plot(y, beta.pdf(y, b, a),'r-', lw=5, alpha=0.6, label='two red')\n",
    "ax[0].hist(two_r, density=True)\n",
    "ax[1].plot(y, beta.pdf(y, b, a),'r-', lw=5, alpha=0.6, label='two green')\n",
    "ax[1].hist(two_g, density=True)\n",
    "ax[2].plot(x, beta.pdf(x, a, b),'r-', lw=5, alpha=0.6, label='two blue')\n",
    "ax[2].hist(two_b, density=True)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4802a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
